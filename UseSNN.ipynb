{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UseSNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q8WCJHlA_qu969Yrk13GNOybDX5W9ZDm",
      "authorship_tag": "ABX9TyOiBS/sKu4xQFqmq30woH/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbqpark/tinger/blob/main/UseSNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KazUpslTC0bR"
      },
      "source": [
        "# **Code to use Siamese Neural Network** \n",
        "\n",
        "**This notebook houses all the functions to use our siamese neural network within the larger Tinger model stack. For further instructions, refer to the Tinger Integration notebook.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNiS8-Y8P27F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe470f1-2562-4e43-b965-f1c9b96e414b"
      },
      "source": [
        "# Mount Google Drive to access directory\n",
        "from google.colab import drive, auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import gspread\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHqid8oO8bY_"
      },
      "source": [
        "# Get authentication to read CSV files from Google Drive\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Bq3c8ACw66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd43be4-acb4-42ab-e888-d8997ffa6ac8"
      },
      "source": [
        "# Install libraries not local to Colab\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-gpu\n",
        "!pip install chinese-converter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (56.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (56.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.28.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: chinese-converter in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kfGdDhO9CW0"
      },
      "source": [
        "# Install all other dependencies\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import chinese_converter\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9IolP1V-BHI"
      },
      "source": [
        "# Fetch standardized title and spectrogram data of a target song\n",
        "def fetch_target(target_title, mel_path, direction):\n",
        "  target_title = target_title\n",
        "  if direction == 0:\n",
        "    target_title = chinese_converter.to_simplified(target_title)\n",
        "  mel_path = mel_path\n",
        "  raw_files = os.listdir(mel_path)\n",
        "\n",
        "  # Convert titles to simplified Mandarin to match substring in strings for Mandarin songs\n",
        "  if direction == 0:\n",
        "    target_mel = []\n",
        "    target_titles = []\n",
        "    for r in raw_files:\n",
        "      if target_title.lower() in chinese_converter.to_simplified(r).lower():\n",
        "        target_mel.append(r)\n",
        "        target_titles.append(target_title+r[-10:])\n",
        "        if len(target_mel) == 5:\n",
        "          break\n",
        "\n",
        "  # Convert titles to lowercase to match substring in strings for English songs\n",
        "  if direction == 1:\n",
        "    target_mel = []\n",
        "    target_titles = []\n",
        "    for r in raw_files:\n",
        "      if target_title.lower() in r.lower():\n",
        "        target_mel.append(r)\n",
        "        target_titles.append(target_title+r[-10:])\n",
        "        if len(target_mel) == 5:\n",
        "          break\n",
        "\n",
        "  # Need to sort file names to ensure indexing is correct later in the stack\n",
        "  target_mel.sort()\n",
        "  target_titles.sort()\n",
        "\n",
        "  # Convert raw spectrogram into input data\n",
        "  target_data = []\n",
        "  for m in target_mel:\n",
        "    to_append = np.asarray(Image.open(os.path.join(mel_path, m)).convert('L').resize((200, 200)))\n",
        "    target_data.append(to_append.reshape((200, 200, 1)))\n",
        "  \n",
        "  target_data = np.asarray(target_data)/255.0\n",
        "  return (target_titles, target_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxLmu7DLHKDr"
      },
      "source": [
        "# Fetch standardized titles and spectrogram data for all comparison songs in the opposite language of the target song\n",
        "def fetch_comparison(mel_path, csv_path, direction):\n",
        "  # Get standardized English or Mandarin titles based on recommendation direction\n",
        "  csv_path = csv_path\n",
        "  df_standard = pd.read_csv(csv_path)\n",
        "  standard_titles = df_standard['Song Title']\n",
        "\n",
        "  # Raw Youtube titles\n",
        "  raw_titles = os.listdir(mel_path)\n",
        "  raw_titles.sort()\n",
        "\n",
        "  # Filter for missing files and standardize names\n",
        "  # Simulatenously collect spectrogram data for files in same index\n",
        "  comparison_titles = []\n",
        "  comparison_data = []\n",
        "\n",
        "  # Convert titles to lowercase to match substring in strings for English songs\n",
        "  if direction == 0:\n",
        "    for r in raw_titles:\n",
        "      for s in standard_titles:\n",
        "        if s.lower() in r.lower():\n",
        "          comparison_titles.append(s+r[-10:])\n",
        "          spec_data = np.asarray(Image.open(os.path.join(mel_path, r)).convert('L').resize((200, 200)))\n",
        "          comparison_data.append(spec_data.reshape((200, 200, 1)))\n",
        "          break\n",
        "\n",
        "  # Convert titles to simplified Mandarin to match substring in strings for Mandarin songs\n",
        "  if direction == 1:\n",
        "    for r in raw_titles:\n",
        "      for s in standard_titles:\n",
        "        s = chinese_converter.to_simplified(s).lower()\n",
        "        if s in chinese_converter.to_simplified(r).lower():\n",
        "          comparison_titles.append(s+r[-10:])\n",
        "          spec_data = np.asarray(Image.open(os.path.join(mel_path, r)).convert('L').resize((200, 200)))\n",
        "          comparison_data.append(spec_data.reshape((200, 200, 1)))\n",
        "          break\n",
        "  \n",
        "  comparison_data = np.asarray(comparison_data)/255.0\n",
        "  \n",
        "  return (comparison_titles, comparison_data)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrfl34D6qOOT"
      },
      "source": [
        "def similarities_matrix(snn_path, mandarin_mel_path, english_mel_path, csv_path, target_title, direction):\n",
        "\n",
        "  \"\"\"\n",
        "  Function that takes in a trained siamese neural network, a target song, and the direction in which we are calculating similarities: i.e. Mandarin >> English\n",
        "\n",
        "  The function outputs a dictionary with song titles as keys and similarity scores are values\n",
        "  \n",
        "  Target_title should be in string form\n",
        "\n",
        "  Direction is a 0/1 boolean value (0 = Mandarin >> English, 1 = English >> Mandarin)\n",
        "\n",
        "  CSV file path is that of the comparison titles\n",
        "  \"\"\"\n",
        "  \n",
        "  snn = keras.models.load_model(snn_path)\n",
        "  target_title = target_title\n",
        "  direction = direction\n",
        "\n",
        "  # Identify path to mel spectrograms\n",
        "  mandarin_mel_path = mandarin_mel_path\n",
        "  english_mel_path = english_mel_path\n",
        "\n",
        "  if direction == 0:\n",
        "    target_title, target_data = fetch_target(target_title, mandarin_mel_path, direction=direction)\n",
        "    comparison_title, comparison_data = fetch_comparison(english_mel_path, csv_path, direction=direction)\n",
        "\n",
        "  else:\n",
        "    target_title, target_data = fetch_target(target_title, mandarin_mel_path, direction=direction)\n",
        "    comparison_title, comparison_data = fetch_comparison(english_mel_path, csv_path, direction=direction)\n",
        "\n",
        "  # Pre-load SNN input with zero arrays\n",
        "  # to_predict[0] is the target song's spectrogram data\n",
        "  # to_predict[1] is a list of len(comparison_data) where each element is the spectogram data for all songs in the other language\n",
        "  to_predict = []\n",
        "  to_predict.append(np.zeros((len(comparison_data), 200, 200, 1)))\n",
        "  to_predict.append(np.zeros((len(comparison_data), 200, 200, 1)))\n",
        "\n",
        "  results = []\n",
        "\n",
        "  # Calcualte model predictions of each spectrogram (5 total) for the target song across all target data\n",
        "  for n in range(5):\n",
        "    for i in range(len(comparison_data)):\n",
        "      to_predict[0][i] = target_data[n]\n",
        "      to_predict[1][i] = comparison_data[i]\n",
        "    \n",
        "    result = snn.predict(to_predict)\n",
        "    result = result.flatten().tolist()\n",
        "    results.append(result)\n",
        "  \n",
        "  results_matrix = np.matrix(results)\n",
        "\n",
        "  return [results_matrix, target_title, target_data, comparison_title, comparison_data]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9FwEHEMYRi6"
      },
      "source": [
        "def generate_heatmap(mat, n_row=5, n_col=40, save_path=None):\n",
        "\n",
        "  \"\"\"\n",
        "  Creates a heat map visualization given a Tinger similarities matrix\n",
        "\n",
        "  Can select the number of rows and columns to create a slice of the matrix\n",
        "  \n",
        "  Default (recommended) values are N_ROWS=5 and N_COL=80\n",
        "  \"\"\"\n",
        "  \n",
        "  extract = mat[0:n_row,0:n_col]\n",
        "\n",
        "  plt.figure(figsize=(40, 20))\n",
        "  plt.imshow(extract, cmap='hot', interpolation='nearest')\n",
        "  plt.title('Mel Spectrogram Similarities Matrix')\n",
        "  plt.ylabel('Target Song Slice #')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  if save_path == None:\n",
        "    return\n",
        "  else:\n",
        "    plt.savefig(save_path)\n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35M_TS0a4dR"
      },
      "source": [
        "def similarities_dict(sim_mat, comparison_titles):\n",
        "\n",
        "  \"\"\"\n",
        "  Takes in a similarities matrix (see similarities_matrix() above) along with the list of all song titles used to compare to target input song.\n",
        "\n",
        "  Calculates the average of all N similarity measures (where N = number of spectrograms per song) to arrive at the final similarity score per song.\n",
        "\n",
        "  Output a dictionary with comparison song titles as keys and their similarity scores as values.\n",
        "  \"\"\"\n",
        "  \n",
        "  mat = sim_mat\n",
        "  comparison_titles = comparison_titles\n",
        "  n_songs = sim_mat.shape[1] / 5\n",
        "\n",
        "  key = []\n",
        "  val = []\n",
        "  index = 0\n",
        "  for i in range(int(n_songs)):\n",
        "    key.append(comparison_titles[index][:-10])\n",
        "    to_append = mat[0:5,index:index+4]\n",
        "    val.append(to_append.mean())\n",
        "    index += 5\n",
        "  \n",
        "  result = dict(zip(key, val))\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}