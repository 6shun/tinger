{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "RomanceLyricsAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbqpark/tinger/blob/main/RomanceLyricsAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7cSfIFEQRld"
      },
      "source": [
        "#**Uses a Random Forest model to classify song lyrics as romance/non-romance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDngTa5lWdh_",
        "outputId": "b4c68be9-59dd-4926-d0c4-6c72bb39aa3f"
      },
      "source": [
        "# import Beautiful Soup, NumPy and Pandas, etc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import hashlib\n",
        " \n",
        "# download NLTK classifiers - these are cached locally on your machine\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# import ml classifiers\n",
        "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
        "from nltk.stem import PorterStemmer     # parsing/stemmer\n",
        "from nltk.tag import pos_tag            # parts-of-speech tagging\n",
        "from nltk.corpus import wordnet         # sentiment scores\n",
        "from nltk.stem import WordNetLemmatizer # stem and context\n",
        "from nltk.corpus import stopwords       # stopwords\n",
        "from nltk.util import ngrams            # ngram iterator\n",
        "\n",
        "# import word2vec\n",
        "from gensim.test.utils import datapath\n",
        "from gensim import utils\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize, FunctionTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBQs7tDs5xqk"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Import English dataset - first 100 is for training, the rest are unlabelled\n",
        "link = 'https://drive.google.com/file/d/1xfCgqZg0LTq9IKIEP5Ckm3B0Lid5EYLX/view?usp=sharing'\n",
        "id = '1xfCgqZg0LTq9IKIEP5Ckm3B0Lid5EYLX'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Filename.csv')  \n",
        "english_playlist = pd.read_csv('Filename.csv')[['Song Title', 'Lyrics', 'Romance']]\n",
        "english_playlist_train = pd.read_csv('Filename.csv')[['Song Title', 'Lyrics', 'Romance']].head(100)\n",
        "\n",
        "# Import Mandarin dataset  - first 100 is for training, the rest are unlabelled\n",
        "link = 'https://drive.google.com/file/d/1U3m4k6HvKgS2S48S7Zwt8qZH5oxdpnC4/view?usp=sharing'\n",
        "id = '1U3m4k6HvKgS2S48S7Zwt8qZH5oxdpnC4'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Filename.csv') \n",
        "mandarin_playlist_train = pd.read_csv('Filename.csv')[['Song Title','Translated Lyrics ', 'Romance']]\n",
        "mandarin_playlist = mandarin_playlist.rename(columns = {'Translated Lyrics ':'Lyrics'})\n",
        "mandarin_playlist_train = mandarin_playlist.rename(columns = {'Translated Lyrics ':'Lyrics'}).head(100)\n",
        "\n",
        "# Join two datasets into one\n",
        "frames = [english_playlist_train, mandarin_playlist_train]\n",
        "data = pd.concat(frames, ignore_index = True)\n",
        "data = data.dropna()\n",
        "data = data.astype({'Romance': 'int64'})\n",
        "\n",
        "\n",
        "full_frames = [english_playlist, mandarin_playlist]\n",
        "full_data = pd.concat(full_frames, ignore_index = True)\n",
        "full_data = full_data.dropna()\n",
        "full_data = full_data.astype({'Romance': 'int64'})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghGB6oIgWdiA"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "eng_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def lyrics_cleaner(lyrics, lemmatize=True, stem=False):\n",
        "\n",
        "    if lemmatize == True and stem == True:\n",
        "        raise RuntimeError(\"May not pass both lemmatize and stem flags\")\n",
        "\n",
        "    # Remove punctuation\n",
        "    lyrics = re.sub(r'[:\"\".!?\\\\-]', '', lyrics)\n",
        "\n",
        "    # Tokenize into words (all lower case)\n",
        "    lyrics = lyrics.lower().split()\n",
        "\n",
        "    # Remove stopwords, Lemmatize, Stem\n",
        "    filtered_sentence = [wnl.lemmatize(w) for w in lyrics if not w in eng_stopwords]\n",
        "    stemmed_sentence = []\n",
        "    for w in filtered_sentence:\n",
        "        w = ps.stem(w)\n",
        "        stemmed_sentence.append(w)\n",
        "\n",
        "    # Join the lyrics to one sentence\n",
        "    lyrics_processed = ' '.join(stemmed_sentence)\n",
        "    \n",
        "    return lyrics_processed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9bTR59FWdiB"
      },
      "source": [
        "def get_vectorizer(ngram, max_features):\n",
        "    return CountVectorizer(ngram_range=(1, ngram),\n",
        "                             analyzer = \"word\",\n",
        "                             preprocessor = lyrics_cleaner,\n",
        "                             max_features = max_features)\n",
        "\n",
        "# Model training\n",
        "def train_predict_sentiment(lyrics, vectorizer, y = data[\"Romance\"], ngram=1, max_features=1000, model_random_state=0):\n",
        "\n",
        "    print(\"Creating the model!\\n\")\n",
        "    \n",
        "    # train / test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(lyrics, y, random_state = 0, test_size = .2)\n",
        "\n",
        "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
        "    # then transform the data into feature vectors.\n",
        "    # The input should be a list of strings. .toarray() converts to a numpy array\n",
        "    \n",
        "    train_bag = vectorizer.fit_transform(X_train)\n",
        "    if not isinstance(train_bag, np.ndarray):\n",
        "        train_bag = train_bag.toarray()\n",
        "\n",
        "    test_bag = vectorizer.transform(X_test)\n",
        "    if not isinstance(test_bag, np.ndarray):\n",
        "        test_bag = test_bag.toarray()\n",
        "\n",
        "    print(\"Training the random forest classifier!\\n\")\n",
        "    # Initialize a Random Forest classifier with 50 trees\n",
        "    forest = RandomForestClassifier(n_estimators = 50, random_state = model_random_state) \n",
        "\n",
        "    # Fit the forest to the training set, using the bag of words as \n",
        "    # features and the sentiment labels as the target variable\n",
        "    forest = forest.fit(train_bag, y_train)\n",
        "\n",
        "    # predict\n",
        "    train_predictions = forest.predict(train_bag)\n",
        "    test_predictions = forest.predict(test_bag)\n",
        "    \n",
        "    # validation\n",
        "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
        "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
        "    \n",
        "    print(\" The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
        "    print()\n",
        "    print('CONFUSION MATRIX:')\n",
        "    print('         Predicted')\n",
        "    print('          neg pos')\n",
        "    print(' Actual')\n",
        "    c=confusion_matrix(y_test, test_predictions)\n",
        "    print('     neg  ',c[0])\n",
        "    print('     pos  ',c[1])\n",
        "\n",
        "    return forest\n",
        "\n",
        "# Print out the top features\n",
        "def top_features(forest, vectorizer, n):\n",
        "    #Extract feature importance\n",
        "    print('\\nTOP TEN IMPORTANT FEATURES:')\n",
        "    feature_text = vectorizer.get_feature_names().copy()\n",
        "    feature_importance = forest.feature_importances_.copy()\n",
        "    \n",
        "    indices = np.argsort(feature_importance)[::-1]\n",
        "    \n",
        "    top_n_ind = indices[:n]\n",
        "    top_n = list([vectorizer.get_feature_names()[ind] for ind in top_n_ind])\n",
        "    \n",
        "    return top_n\n",
        "\n",
        "# Print out whether the prediction is accurate\n",
        "def check_prediction(model, vectorizer, review, expected):\n",
        "    prediction = model.predict(vectorizer.transform([review]))[0]\n",
        "    sentiment = \"\\n👍\" if prediction else \"\\n👎\"\n",
        "    correct = \"\\x1b[92mcorrect\\x1b[0m\" if prediction == expected else \"\\x1b[31mincorrect\\x1b[0m\"\n",
        "    print(\"{} ⟶ {} {}\".format(review, sentiment, correct))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ4QWMgCWdiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0625b3f9-f418-40db-de89-0fb53b54038d"
      },
      "source": [
        "vectorizer = get_vectorizer(1, 100)\n",
        "forest_model = train_predict_sentiment(data[\"Lyrics\"], vectorizer, max_features=100)\n",
        "top_10 = top_features(forest_model, vectorizer, 10)\n",
        "print(top_10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the model!\n",
            "\n",
            "Training the random forest classifier!\n",
            "\n",
            " The training accuracy is:  1.0 \n",
            " The validation accuracy is:  0.7\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "         Predicted\n",
            "          neg pos\n",
            " Actual\n",
            "     neg   [11  9]\n",
            "     pos   [ 3 17]\n",
            "\n",
            "TOP TEN IMPORTANT FEATURES:\n",
            "['love', 'like', 'face', 'peopl', 'world', 'go', 'way', 'want', 'light', 'miss']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "3IodHzGIEF2m",
        "outputId": "46bb9fb8-1b65-4a3f-9e3f-3ac348bdbf09"
      },
      "source": [
        "data_vectorized = vectorizer.transform(full_data['Lyrics'])\n",
        "if not isinstance(data_vectorized, np.ndarray):\n",
        "        data_vectorized = data_vectorized.toarray()\n",
        "full_predictions = forest_model.predict(data_vectorized)\n",
        "pd.DataFrame(full_predictions, full_data['Song Title'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Song Title</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>We Are Young</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Save Your Tears</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Blinding Lights</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rain on me</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Intentions</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>水调歌头</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>淒美地</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>你是如此难以忘记</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>致姍姍來遲的你</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>我最親愛的</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>422 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0\n",
              "Song Title        \n",
              "We Are Young     0\n",
              "Save Your Tears  1\n",
              "Blinding Lights  1\n",
              "Rain on me       0\n",
              "Intentions       1\n",
              "...             ..\n",
              "水调歌头             0\n",
              "淒美地              1\n",
              "你是如此难以忘记         1\n",
              "致姍姍來遲的你          0\n",
              "我最親愛的            1\n",
              "\n",
              "[422 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxvfArP6WdiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26805838-f8c7-4664-cc65-02cf95c9c6cf"
      },
      "source": [
        "romantic_song = \"I found a love for me Oh darling, just dive right in and follow my lead Well, I found a girl, beautiful and sweet Oh, I never knew you were the someone waiting for me 'Cause we were just kids when we fell in love Not knowing what it was I will not give you up this time But darling, just kiss me slow, your heart is all I own And in your eyes, you're holding mine Baby, I'm dancing in the dark with you between my arms Barefoot on the grass, listening to our favourite song When you said you looked a mess, I whispered underneath my breath But you heard it, darling, you look perfect tonight Well I found a woman, stronger than anyone I know She shares my dreams, I hope that someday I'll share her home I found a love, to carry more than just my secrets To carry love, to carry children of our own We are still kids, but we're so in love Fighting against all odds I know we'll be alright this time Darling, just hold my hand Be my girl, I'll be your man I see my future in your eyes Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song When I saw you in that dress, looking so beautiful I don't deserve this, darling, you look perfect tonight Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song I have faith in what I see Now I know I have met an angel in person And she looks perfect I don't deserve this You look perfect tonight\"\n",
        "check_prediction(forest_model, vectorizer, romantic_song, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I found a love for me Oh darling, just dive right in and follow my lead Well, I found a girl, beautiful and sweet Oh, I never knew you were the someone waiting for me 'Cause we were just kids when we fell in love Not knowing what it was I will not give you up this time But darling, just kiss me slow, your heart is all I own And in your eyes, you're holding mine Baby, I'm dancing in the dark with you between my arms Barefoot on the grass, listening to our favourite song When you said you looked a mess, I whispered underneath my breath But you heard it, darling, you look perfect tonight Well I found a woman, stronger than anyone I know She shares my dreams, I hope that someday I'll share her home I found a love, to carry more than just my secrets To carry love, to carry children of our own We are still kids, but we're so in love Fighting against all odds I know we'll be alright this time Darling, just hold my hand Be my girl, I'll be your man I see my future in your eyes Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song When I saw you in that dress, looking so beautiful I don't deserve this, darling, you look perfect tonight Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song I have faith in what I see Now I know I have met an angel in person And she looks perfect I don't deserve this You look perfect tonight ⟶ \n",
            "👍 \u001b[92mcorrect\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy3XaUXkWdiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ffb75a-fb41-4f67-d857-d06e6d11c627"
      },
      "source": [
        "non_romantic_song = \"Feeling my way through the darkness Guided by a beating heart I can't tell where the journey will end But I know where to start They tell me I'm too young to understand They say I'm caught up in a dream Well life will pass me by if I don't open up my eyes Well that's fine by me So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I tried carrying the weight of the world But I only have two hands Hope I get the chance to travel the world But I don't have any plans Wish that I could stay forever this young Not afraid to close my eyes Life's a game made for everyone And love is a prize So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know, I didn't know, I didn't know\"\n",
        "check_prediction(forest_model, vectorizer, non_romantic_song, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feeling my way through the darkness Guided by a beating heart I can't tell where the journey will end But I know where to start They tell me I'm too young to understand They say I'm caught up in a dream Well life will pass me by if I don't open up my eyes Well that's fine by me So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I tried carrying the weight of the world But I only have two hands Hope I get the chance to travel the world But I don't have any plans Wish that I could stay forever this young Not afraid to close my eyes Life's a game made for everyone And love is a prize So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know, I didn't know, I didn't know ⟶ \n",
            "👎 \u001b[92mcorrect\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roENAihrWdiE"
      },
      "source": [
        "w2v_model = Word2Vec(sentences=[utils.simple_preprocess(lyrics) for lyrics in data['Lyrics']], size=100, workers=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auTJU6bpWdiE"
      },
      "source": [
        "def get_avg_feature_vecs(reviews, model):\n",
        "    # Given a set of reviews (each one a list of words), calculate \n",
        "    # the average feature vector for each one \n",
        "\n",
        "    \n",
        "    # Index2word is a list that contains the names of the words in \n",
        "    # the model's vocabulary. Convert it to a set, for speed \n",
        "    index2word_set = set(model.wv.index2word)\n",
        "    \n",
        "    reviewFeatureVecs = []\n",
        "    # Loop through the reviews\n",
        "    for counter, review in enumerate(reviews):\n",
        "        \n",
        "        # Print a status message every 5000th review\n",
        "        if (counter + 1) % 5000. == 0.:\n",
        "            print(\"Review %d of %d\" % (counter + 1, len(reviews)))\n",
        "\n",
        "        # Function to average all of the word vectors in a given paragraph\n",
        "        featureVec = []\n",
        "\n",
        "        # Loop over each word in the review and, if it is in the model's\n",
        "        # vocaublary, add its feature vector to the total        \n",
        "        for n,word in enumerate(utils.simple_preprocess(review)):\n",
        "            if word in index2word_set: \n",
        "                featureVec.append(model.wv[word])\n",
        "\n",
        "        \n",
        "        \n",
        "        # Average the word vectors\n",
        "        featureVec = np.mean(featureVec, axis=0).reshape(1,-1)\n",
        "\n",
        "        reviewFeatureVecs.append(featureVec)\n",
        "\n",
        "    return np.concatenate(reviewFeatureVecs, axis=0)\n",
        "\n",
        "w2v_vectorizer = FunctionTransformer(lambda x: get_avg_feature_vecs(x, w2v_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahqXt7XXWdiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88884778-458f-4678-cfca-638c9ee1d4bd"
      },
      "source": [
        "w2v_forest_model = train_predict_sentiment(data['Lyrics'], w2v_vectorizer, max_features=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the model!\n",
            "\n",
            "Training the random forest classifier!\n",
            "\n",
            " The training accuracy is:  1.0 \n",
            " The validation accuracy is:  0.525\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "         Predicted\n",
            "          neg pos\n",
            " Actual\n",
            "     neg   [11  9]\n",
            "     pos   [10 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL8tRraIWdiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b90bf05-1740-4df2-b193-8b95661e3368"
      },
      "source": [
        "check_prediction(w2v_forest_model, vectorizer, non_romantic_song, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feeling my way through the darkness Guided by a beating heart I can't tell where the journey will end But I know where to start They tell me I'm too young to understand They say I'm caught up in a dream Well life will pass me by if I don't open up my eyes Well that's fine by me So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I tried carrying the weight of the world But I only have two hands Hope I get the chance to travel the world But I don't have any plans Wish that I could stay forever this young Not afraid to close my eyes Life's a game made for everyone And love is a prize So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost So wake me up when it's all over When I'm wiser and I'm older All this time I was finding myself And I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know I was lost I didn't know, I didn't know, I didn't know ⟶ \n",
            "👎 \u001b[92mcorrect\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFiuAxylWdiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd3d877-0fd6-4381-c91c-4923ab750ee8"
      },
      "source": [
        "check_prediction(w2v_forest_model, vectorizer, romantic_song, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I found a love for me Oh darling, just dive right in and follow my lead Well, I found a girl, beautiful and sweet Oh, I never knew you were the someone waiting for me 'Cause we were just kids when we fell in love Not knowing what it was I will not give you up this time But darling, just kiss me slow, your heart is all I own And in your eyes, you're holding mine Baby, I'm dancing in the dark with you between my arms Barefoot on the grass, listening to our favourite song When you said you looked a mess, I whispered underneath my breath But you heard it, darling, you look perfect tonight Well I found a woman, stronger than anyone I know She shares my dreams, I hope that someday I'll share her home I found a love, to carry more than just my secrets To carry love, to carry children of our own We are still kids, but we're so in love Fighting against all odds I know we'll be alright this time Darling, just hold my hand Be my girl, I'll be your man I see my future in your eyes Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song When I saw you in that dress, looking so beautiful I don't deserve this, darling, you look perfect tonight Baby, I'm dancing in the dark, with you between my arms Barefoot on the grass, listening to our favorite song I have faith in what I see Now I know I have met an angel in person And she looks perfect I don't deserve this You look perfect tonight ⟶ \n",
            "👍 \u001b[92mcorrect\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3YNlS2aWdiF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}